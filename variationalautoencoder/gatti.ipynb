{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4862ec7-2e5f-453e-bd39-40cf5e0b2848",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyberguli/.conda/envs/sissa/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import stl\n",
    "import pulp as plp\n",
    "from stl import mesh\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1555c9c6-307c-4232-b187-fa4ffd539604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(x,y,z):\n",
    "        return np.arccos(np.sum((x-y)*(x-z))/(np.linalg.norm(x-y)*np.linalg.norm(x-z)))\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "def unique(list1):\n",
    " \n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    \n",
    "    return unique_list\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8ef031-6426-452f-a21a-1b461cc5450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRIMD(reference,deformed):\n",
    "    print('getting reference')\n",
    "    #gets point and implicit neighbouroods of reference\n",
    "    your_mesh0 = mesh.Mesh.from_file(reference)\n",
    "    temp0=your_mesh0.data[0][1]\n",
    "    for i in range(1,len(your_mesh0.data)):\n",
    "        temp0=np.concatenate((temp0,your_mesh0.data[i][1]), axis=0)\n",
    "    Pointset0 = np.unique(temp0, axis=0)\n",
    "    neigh0=[]\n",
    "    N=len(Pointset0)\n",
    "    for i in range(len(Pointset0)):\n",
    "        lst=[]\n",
    "        for j in range(len(your_mesh0.data)):\n",
    "            if Pointset0[i].tolist() in your_mesh0.data[j][1].tolist():\n",
    "                for k in range(3):\n",
    "                    if Pointset0[i].tolist()!=your_mesh0.data[j][1][k].tolist():\n",
    "                        lst.append(your_mesh0.data[j][1][k].tolist())\n",
    "        lst=unique(lst)\n",
    "        neigh0.append(lst)\n",
    "    neigh0=unique(neigh0)\n",
    "    #gets point and and neigh of deformed\n",
    "    print('getting deformed')\n",
    "    your_mesh1 = mesh.Mesh.from_file(deformed)\n",
    "    temp1=your_mesh1.data[0][1]\n",
    "    for i in range(1,len(your_mesh1.data)):\n",
    "        temp1=np.concatenate((temp1,your_mesh1.data[i][1]), axis=0)\n",
    "    Pointset1 = np.unique(temp1, axis=0)\n",
    "    neigh1=[]\n",
    "    for i in range(N):\n",
    "        lst=[]\n",
    "        for j in range(len(your_mesh1.data)):\n",
    "            if Pointset1[i].tolist() in your_mesh1.data[j][1].tolist():\n",
    "                for k in range(3):\n",
    "                    if Pointset1[i].tolist()!=your_mesh1.data[j][1][k].tolist():\n",
    "                        lst.append(your_mesh1.data[j][1][k].tolist())\n",
    "                        lst=unique(lst)\n",
    "        neigh1.append(lst)\n",
    "        neigh1=unique(neigh1)\n",
    "     #calculates the matrix of the angles\n",
    "    C=np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i!=j:\n",
    "                temp=intersection(neigh0[i],neigh0[j])\n",
    "                if len(temp)==2:\n",
    "                    C[i,j]=abs(1/np.tan(calculate_angle(temp[0],Pointset0[i],Pointset0[j])))+abs(1/np.tan(calculate_angle(temp[1],Pointset0[i],Pointset0[j])))\n",
    "    #calculates real neigh\n",
    "    print('calculating real neigh')\n",
    "    neigh=[1]*N\n",
    "    for i in range(N):\n",
    "        neigh[i]=[j for j in range(N) if C[i,j]!=0]\n",
    "    print('calculating T')\n",
    "    #calculates T\n",
    "    T=np.zeros([N,3,3])\n",
    "    for i in range(N):\n",
    "        for a in range(3):\n",
    "            for b in range(3):\n",
    "                temp0=0\n",
    "                temp1=0\n",
    "                for j in neigh[i]: \n",
    "                        p0=Pointset0[i]-Pointset0[j]\n",
    "                        p1=Pointset1[i]-Pointset1[j]\n",
    "                        temp0=temp0+C[i,j]*p0[b]*p1[a]\n",
    "                        temp1=temp1+C[i,j]*p0[b]*p0[b]\n",
    "                T[i,a,b]=temp0/temp1\n",
    "    #T=np.nan_to_num(T,nan=1)\n",
    "    R=np.zeros([N,3,3])\n",
    "    S=np.zeros([N,3,3])\n",
    "    dR=np.zeros([N,N,3,3])\n",
    "    temp=np.zeros([N,3,3])\n",
    "    print('calculating R and S')\n",
    "    #calculates R and S\n",
    "    for i in range(N):\n",
    "        temp[i]=np.matmul(T[i].T,T[i])\n",
    "        D,Q=np.linalg.eigh(temp[i])\n",
    "        D=np.diag(D)**0.5\n",
    "        #D=np.nan_to_num(D,nan=1)\n",
    "        S[i]=np.matmul(Q.T,np.matmul(D,Q))\n",
    "        R[i]=np.matmul(T[i],np.linalg.inv(S[i]))\n",
    "        R[i][R[i]==np.inf] = 999\n",
    "\n",
    "    print('calculating RIMD')\n",
    "    RIMDi0=S[0]\n",
    "    for j in neigh[0]:\n",
    "        dR[0][j]=np.matmul(R[0].T,R[j])\n",
    "        RIMDi0=np.concatenate((dR[0,j],RIMDi0),axis=1)\n",
    "    RIMD=RIMDi0\n",
    "    for i in range(N):\n",
    "        RIMDi=S[i]\n",
    "        for j in neigh[i]:\n",
    "            dR[i][j]=np.matmul(R[i].T,R[j])\n",
    "            RIMDi=np.concatenate((dR[i,j],RIMDi),axis=1)\n",
    "        RIMD=np.concatenate((RIMD,RIMDi),axis=1)\n",
    "    M=len(RIMD[0,:])\n",
    "    RIMD=RIMD.reshape(3*M)\n",
    "    E=np.zeros([N,N,3])\n",
    "    for i in range(N):\n",
    "        for j in neigh[i]:\n",
    "            E[i,j,:]=Pointset0[i]-Pointset0[j]\n",
    "    shape=np.zeros([len(your_mesh0.data),3])\n",
    "    for i in range(len(your_mesh0.data)):\n",
    "        for k in range(3):\n",
    "            for j in range(len(Pointset0)):\n",
    "                if your_mesh0.data[i][1][k].tolist()==Pointset0[j].tolist():\n",
    "                    shape[i,k]=j\n",
    "                   \n",
    "    \n",
    "    return RIMD,neigh,E,C,shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efd8e62-33b5-4145-99e3-f47519a7de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_STL(newRIMD,neigh,E,C,shape,name):\n",
    "    newRIMD=newRIMD.reshape(3,int(len(newRIMD)/3))\n",
    "    N=len(neigh)\n",
    "    newS=np.zeros([N,3,3])\n",
    "    newdR=np.zeros([N,N,3,3])\n",
    "    k=0\n",
    "    for i in range(len(neigh)):\n",
    "        for j in neigh[i]:\n",
    "            newdR[i,j]=np.exp(newRIMD[:,k:k+3])\n",
    "            k=k+3\n",
    "        newS[i]=newRIMD[:,k:k+3]\n",
    "\n",
    "    newR=np.zeros([N,3,3])\n",
    "    for i in range(N):\n",
    "        newR[i,:,:]=np.eye(3)\n",
    "\n",
    "    Energy=1\n",
    "    Energyold=0\n",
    "    while abs(Energy-Energyold)/abs(Energy)>0.03:\n",
    "        opt_model = plp.LpProblem()\n",
    "        Ctilde=np.zeros(N)\n",
    "        for i in range(N):\n",
    "            Ctilde[i]=1/len(neigh[i])\n",
    "        x_vars  = {(i,h): plp.LpVariable(cat=plp.LpContinuous,  \n",
    "               name=\"x_{0}_{1}\".format(i,h)) for i in range(N) for h in range(3)}\n",
    "\n",
    "        temp=np.zeros([N,3])\n",
    "        for j in range(N):\n",
    "            for k in neigh[j]:\n",
    "                temp3=0\n",
    "                temp0=0\n",
    "                temp1=0\n",
    "                for s in neigh[k]:\n",
    "                    temp0=temp0+Ctilde[k]*np.matmul(newR[s],np.matmul(newdR[s,k],newS[k]))\n",
    "                for i in neigh[j]:\n",
    "                    temp1=temp1+Ctilde[j]*np.matmul(newR[i],np.matmul(newdR[i,j],newS[j]))\n",
    "                temp3=temp3+C[j,k]*np.matmul(temp0+temp1,E[j,k])\n",
    "            temp[j,:]=temp3\n",
    "\n",
    "        constraints = {j : opt_model.addConstraint(\n",
    "        plp.LpConstraint(\n",
    "             e=plp.lpSum(C[j,k] * (x_vars[j,h]-x_vars[k,h] )for k in neigh[j]),\n",
    "             sense=plp.LpConstraintEQ,\n",
    "             rhs=temp[j][h],\n",
    "             name=\"constraint_{0}_{1}\".format(j,h)))\n",
    "           for j in range(N) for h in range(3)}\n",
    "        opt_model.solve(plp.PULP_CBC_CMD(msg=0))\n",
    "        newP=np.zeros([N,3])\n",
    "        newE=np.zeros([N,N,3])\n",
    "        for i in range(N):\n",
    "            for k in range(3):\n",
    "                newP[i,k]=plp.value(x_vars[i,k])\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                newE[i,j,:]=newP[i,:]-newP[j,:]\n",
    "        Q=np.zeros([N,3,3])\n",
    "        for i in range(N):\n",
    "            temp1=0\n",
    "            for j in neigh[i]:\n",
    "                temp0=0\n",
    "                for k in neigh[j]:\n",
    "                    temp0=temp0+C[j,k]*np.outer(E[j,k],newE[j,k].T)\n",
    "                temp1=temp1+Ctilde[j]*np.matmul(newdR[i,j],np.matmul(newS[i],temp0))\n",
    "            Q[i]=temp1\n",
    "            U, s, Vh = np.linalg.svd(Q[i])\n",
    "            newR[i]=np.matmul(U,Vh)\n",
    "        Energyold=Energy\n",
    "        Energy=0\n",
    "        for i in range(N):\n",
    "            temp1=0\n",
    "            for j in neigh[i]:\n",
    "                temp0=0\n",
    "                for k in neigh[j]:\n",
    "                    temp0=temp0+C[j,k]*np.linalg.norm(newE[j,k]-np.matmul(np.matmul(newR[i],newdR[i,j]),np.matmul(newS[j],E[j,k])))**2\n",
    "                temp1=temp1+Ctilde[j]*temp0\n",
    "            Energy=Energy+temp1\n",
    "\n",
    "    shape=shape.astype(np.int64)\n",
    "    newmesh = np.zeros(len(shape), dtype=mesh.Mesh.dtype)\n",
    "    for i in range(len(shape)):\n",
    "        newmesh['vectors'][i]=np.array([newP[j].tolist() for j in shape[i].tolist()])\n",
    "    mesh.Mesh(newmesh).save(name, mode=stl.Mode.ASCII)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b39bfc-3752-4cde-92eb-b16f0b945871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting reference\n",
      "getting deformed\n",
      "calculating real neigh\n",
      "calculating T\n",
      "calculating R and S\n",
      "calculating RIMD\n"
     ]
    }
   ],
   "source": [
    "RIMD,neigh,E,C,shape=createRIMD('cube.stl','Parallelepiped.stl')\n",
    "def pseudonormalize(data,a):\n",
    "    return 2*a*(data-np.min(data))/(np.max(data)-np.min(data))-a,np.max(RIMD),np.min(RIMD)\n",
    "\n",
    "RIMDtilde,Max,Min=pseudonormalize(RIMD,0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9d29c5-c385-414f-9003-a7231cefb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=432\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, N)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = self.tanh(self.fc21(hidden))\n",
    "        return loc_img\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(N,hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(N)\n",
    "        # compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale\n",
    "\n",
    "        \n",
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super().__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            # decode the latent code z\n",
    "            loc_img = self.decoder(z)\n",
    "            pyro.sample(\"obs\", dist.AffineBeta(loc_img+1,1-loc_img,-1,2).to_event(1), obs=x)\n",
    "            \n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder(x)\n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            \n",
    "    def fitted(self, x):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img\n",
    "\n",
    "def train(svi, train_set, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x in train_set:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "        \n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_set)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train\n",
    "\n",
    "def evaluate(svi, test_set, use_cuda=False):\n",
    "\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for x in test_set:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "\n",
    "        hello=vae.fitted(x)\n",
    "        \n",
    "    return hello\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a652a8a8-d8eb-4795-83e4-35dc2d18a20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(242.3925, dtype=torch.float64)\n",
      "tensor(0.0508, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Run options\n",
    "LEARNING_RATE = 1.0e-3\n",
    "USE_CUDA = False\n",
    "# Run only for a single iteration for testing\n",
    "NUM_EPOCHS = 100000\n",
    "TEST_FREQUENCY = 10\n",
    "\n",
    "train_loader=[]\n",
    "train_loader.append(torch.tensor(RIMDtilde).float())\n",
    "test_loader=train_loader\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=USE_CUDA)\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    #print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "'''\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))\n",
    "'''\n",
    "print(torch.sum(torch.tensor(RIMDtilde)**2))\n",
    "print(torch.sum((torch.tensor(RIMDtilde)-evaluate(svi,train_loader,False))**2)/len(RIMDtilde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07580667-b766-4b76-bdaf-fbf07ac34214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9846703e-01 1.9081434e-03 1.5602510e-03 1.0034020e+00 1.6112460e-03\n",
      " 8.4969733e-04 9.9948150e-01 9.4268058e-04 1.9201306e-03 1.9979892e+00\n",
      " 2.5791593e-03 1.6313791e-03 9.9940658e-01 1.5916427e-03 1.9943053e-03\n",
      " 1.0040286e+00 1.9239718e-03 1.8827784e-03 1.0007813e+00 1.7208523e-03\n",
      " 2.0315913e-03 1.9991419e+00 2.7242636e-03 2.7163161e-03 9.9928910e-01\n",
      " 2.3385552e-03 1.6061466e-03 9.9919391e-01 1.7208523e-03 2.5566421e-03\n",
      " 1.0093318e+00 1.2768640e-03 2.9232767e-03 1.0003083e+00 1.7632379e-03\n",
      " 1.9366874e-03 1.0003645e+00 3.1999748e-03 2.2853746e-03 1.0050844e+00\n",
      " 2.1097395e-03 1.7510520e-04 1.9990780e+00 2.9087730e-03 1.5187926e-03\n",
      " 9.9956959e-01 2.4954479e-03 8.4221363e-04 9.9514049e-01 2.5197533e-03\n",
      " 1.5009112e-03 9.9634379e-01 1.9396676e-03 1.7407206e-03 1.0009160e+00\n",
      " 1.6442273e-03 2.3569665e-03 9.9864137e-01 2.4843880e-03 2.5532644e-03\n",
      " 1.0002307e+00 2.2920636e-03 2.4823349e-03 1.9974322e+00 2.6176374e-03\n",
      " 1.9645030e-03 1.0000933e+00 2.5798879e-03 2.1674237e-03 1.0011040e+00\n",
      " 2.8040675e-03 1.9218525e-03 1.0012401e+00 2.1811328e-03 2.6670431e-03\n",
      " 2.0000000e+00 2.3755762e-03 1.9032425e-03 9.9449170e-01 1.4359421e-03\n",
      " 2.8946004e-03 1.0010396e+00 2.1550390e-03 2.1304025e-03 9.9749464e-01\n",
      " 2.3376942e-03 2.0200678e-03 1.0020245e+00 1.1323558e-03 2.2988850e-03\n",
      " 1.0009035e+00 2.3367009e-03 2.8678444e-03 9.9850774e-01 1.5371376e-04\n",
      " 2.7011500e-03 1.9985862e+00 1.4821027e-03 2.5390254e-03 1.0004129e+00\n",
      " 1.5485287e-03 3.0896401e-03 9.9989349e-01 2.3501450e-03 3.0999715e-03\n",
      " 1.0005481e+00 2.3238526e-03 2.0055638e-03 1.9987795e+00 2.4737916e-03\n",
      " 1.4190542e-03 1.0000511e+00 2.3839208e-03 1.6860830e-03 9.9821961e-01\n",
      " 2.3279588e-03 1.8000603e-03 1.0037879e+00 1.5903182e-03 1.8038353e-03\n",
      " 1.9983799e+00 2.2113987e-03 2.7486351e-03 1.0111206e+00 1.4836258e-03\n",
      " 2.4810766e-03 1.0000044e+00 2.5979017e-03 2.4028621e-03 9.9894208e-01\n",
      " 2.4200811e-03 6.4214075e-04 1.0040736e+00 2.4389559e-03 1.9443035e-03\n",
      " 1.0056634e+00 2.7534035e-03 1.7942323e-03 1.0029422e+00 2.2641819e-03\n",
      " 2.6884344e-03 1.9980882e+00 1.4825662e-03 2.7571784e-03 2.8416184e-03\n",
      " 1.0014975e+00 1.4097823e-03 9.1791153e-04 1.0026841e+00 1.5344223e-03\n",
      " 3.0093724e-03 9.9995780e-01 2.3001432e-03 1.5176005e-03 1.0006366e+00\n",
      " 2.1734503e-03 1.9092030e-03 9.9768925e-01 2.0499362e-03 1.0618899e-03\n",
      " 9.9523699e-01 2.8031403e-03 1.8511879e-03 9.9547070e-01 2.0293396e-03\n",
      " 2.5011434e-03 9.9429113e-01 2.2217301e-03 2.6255846e-03 9.9900556e-01\n",
      " 1.0412269e-03 2.6547248e-03 1.0008056e+00 2.4983620e-03 1.5821722e-03\n",
      " 1.0004280e+00 5.2047491e-16 2.6433999e-03 1.0001349e+00 1.5670724e-03\n",
      " 1.5705824e-03 1.0009276e+00 2.0203325e-03 1.4068021e-03 1.0003276e+00\n",
      " 1.6900566e-03 2.4151141e-03 9.9522108e-01 2.5592248e-03 1.0036097e-03\n",
      " 9.9965227e-01 9.2811056e-04 2.7903584e-03 9.9871862e-01 1.8679434e-03\n",
      " 2.9500327e-03 1.0003021e+00 7.6287327e-04 1.8361543e-03 1.0023134e+00\n",
      " 2.3724637e-03 1.8870831e-03 1.0089364e+00 1.8794669e-03 2.4252469e-03\n",
      " 1.0027903e+00 7.9294050e-04 1.6882023e-03 1.0009847e+00 1.6607179e-03\n",
      " 2.8090344e-03 1.0001388e+00 1.6425716e-03 1.8940370e-03 1.0008438e+00\n",
      " 1.6332997e-03 2.1501384e-03 1.0017266e+00 2.2955074e-03 1.7191304e-03\n",
      " 9.8794866e-01 2.4073655e-03 2.2002063e-03 1.0030671e+00 2.5504827e-03\n",
      " 2.2963684e-03 9.9783319e-01 1.1232165e-03 2.5064417e-03 9.9950224e-01\n",
      " 2.2111998e-03 2.2522609e-03 9.9288130e-01 2.9806297e-03 1.7125077e-03\n",
      " 9.8970270e-01 2.1402703e-03 7.6625083e-04 1.0019661e+00 1.5920401e-03\n",
      " 1.8037028e-03 9.9973482e-01 2.1055671e-03 2.1506681e-03 9.9729955e-01\n",
      " 2.1405353e-03 1.5089910e-03 1.0007168e+00 1.4186568e-03 2.1725893e-03\n",
      " 1.0013005e+00 1.8827784e-03 2.9853319e-03 9.9921721e-01 1.2746785e-03\n",
      " 1.9627148e-03 1.0042896e+00 2.7519464e-03 1.4230941e-03 9.9996531e-01\n",
      " 1.6501878e-03 2.0302667e-03 1.0039796e+00 2.4938583e-03 1.0880497e-03\n",
      " 1.0060607e+00 1.1788474e-03 1.3300446e-03 1.0061857e+00 1.4411741e-03\n",
      " 2.8475788e-03 9.9604487e-01 2.9650663e-03 1.3024940e-03 9.9911273e-01\n",
      " 1.7927754e-03 2.7407540e-03 9.9680591e-01 2.6190944e-03 2.1617280e-03\n",
      " 1.0026655e+00 1.8008550e-03 1.9890070e-03 9.9928838e-01 1.9445685e-03\n",
      " 2.4533272e-03 1.0005068e+00 2.5345883e-03 2.7173758e-03 2.3368332e-03\n",
      " 9.9965191e-01 2.3372306e-03 1.4691883e-03 9.9912977e-01 2.4530625e-03\n",
      " 2.2155710e-03 1.0002880e+00 2.0203325e-03 1.4531612e-03 5.5566108e-01\n",
      " 2.1226539e-03 1.7340978e-03 9.9048060e-01 9.7162195e-04 2.0508633e-03\n",
      " 9.9988806e-01 4.2186843e-04 2.7317472e-03 9.9910420e-01 1.4530950e-03\n",
      " 2.1747749e-03 5.5238098e-01 1.1520253e-03 2.2817983e-03 1.0013534e+00\n",
      " 1.8390683e-03 1.7226405e-03 1.0079269e+00 1.4187230e-03 2.1997425e-03\n",
      " 1.0036498e+00 1.5230974e-03 1.5722382e-03 9.9919885e-01 2.0905337e-03\n",
      " 1.5929673e-03 1.0006576e+00 2.2156371e-03 2.1279522e-03 1.0102049e+00\n",
      " 2.6767785e-03 9.6274749e-04 5.5759257e-01 1.7111832e-03 2.2374259e-03\n",
      " 1.0011857e+00 2.0026499e-03 1.6023716e-03 1.0002236e+00 5.2412355e-04\n",
      " 2.5256476e-03 9.9810094e-01 1.5586615e-03 1.2793144e-03 1.0026205e+00\n",
      " 1.7583370e-03 2.5455819e-03 9.9583232e-01 2.0260282e-03 1.7802584e-03\n",
      " 9.9771035e-01 2.4837255e-03 3.2340155e-03 5.5514467e-01 2.1223228e-03\n",
      " 2.9581785e-03 1.0006019e+00 2.3198128e-03 2.3735894e-03 9.9816716e-01\n",
      " 2.0695396e-03 3.0157964e-03 1.0001373e+00 2.5111437e-03 2.6164453e-03\n",
      " 5.5619884e-01 2.6619434e-03 2.4212070e-03 9.9915552e-01 1.4715063e-03\n",
      " 1.9892720e-03 9.9872327e-01 2.1106668e-03 2.3753115e-03 1.0020406e+00\n",
      " 1.6199219e-03 2.6922093e-03 1.0004424e+00 1.5668737e-03 2.4137232e-03\n",
      " 1.0104524e+00 2.2345781e-03 2.5585627e-03 9.8833007e-01 1.7508534e-03\n",
      " 1.7135012e-03 5.5427724e-01 2.4451150e-03 2.1091434e-03 1.0000181e+00\n",
      " 2.6384990e-03 2.8916202e-03 1.0019512e+00 2.3417340e-03 2.5453172e-03\n",
      " 1.0026469e+00 2.1638474e-03 2.1608672e-03 5.5799246e-01 2.1974246e-03\n",
      " 1.4226966e-03 1.0021491e+00 2.3803446e-03 2.7843318e-03 9.9947804e-01\n",
      " 2.1394095e-03 2.2145114e-03 1.0000081e+00 2.9819543e-03 1.4668703e-03\n",
      " 5.5685133e-01 3.5206479e-04 1.7002557e-03 1.0041041e+00 9.4360777e-04\n",
      " 1.3569992e-03 9.9648702e-01 2.1005340e-03 1.9598671e-03 1.0001426e+00\n",
      " 2.4425983e-03 1.8195974e-03 9.9868435e-01 2.0375517e-03 2.0907985e-03\n",
      " 1.0001094e+00 3.1007000e-03 2.3142498e-03 1.0046843e+00 2.5812124e-03\n",
      " 1.7747615e-03 5.5515623e-01]\n"
     ]
    }
   ],
   "source": [
    "newRIMDtilde=evaluate(svi,train_loader,False)\n",
    "newRIMDtilde=newRIMDtilde.detach().numpy()\n",
    "newRIMDtilde,*_=pseudonormalize(newRIMDtilde,0.9)\n",
    "def pseudodenormalize(data,a,Max,min):\n",
    "    return (data+a)/(2*a)*(Max-Min)-Min\n",
    "\n",
    "newRIMD=pseudodenormalize(newRIMDtilde,0.9,Max,Min)\n",
    "print(newRIMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca148633-a706-4b07-a127-90ef4efeab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_STL(newRIMD,neigh,E,C,shape,'newmesh.stl')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acf74acd-deb6-4161-8b30-a4ed888bdd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "your_mesh0 = mesh.Mesh.from_file(\"cube.stl\")\n",
    "your_mesh1 = mesh.Mesh.from_file(\"Parallelepiped.stl\")\n",
    "your_mesh2 = mesh.Mesh.from_file(\"newmesh.stl\")\n",
    "\n",
    "print(len(your_mesh0))\n",
    "print(len(your_mesh1))\n",
    "print(len(your_mesh2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31bf28-49da-41b8-9060-ebb1fefbd0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39967648-1d04-4cd8-afe3-71b925548cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
