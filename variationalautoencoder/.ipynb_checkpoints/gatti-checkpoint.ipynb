{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4862ec7-2e5f-453e-bd39-40cf5e0b2848",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyberguli/.conda/envs/sissa/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import stl\n",
    "import pulp as plp\n",
    "from stl import mesh\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1555c9c6-307c-4232-b187-fa4ffd539604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(x,y,z):\n",
    "        return np.arccos(np.sum((x-y)*(x-z))/(np.linalg.norm(x-y)*np.linalg.norm(x-z)))\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "def unique(list1):\n",
    " \n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    \n",
    "    return unique_list\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8ef031-6426-452f-a21a-1b461cc5450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRIMD(reference,deformed):\n",
    "    print('getting reference')\n",
    "    #gets point and implicit neighbouroods of reference\n",
    "    your_mesh0 = mesh.Mesh.from_file(reference)\n",
    "    temp0=your_mesh0.data[0][1]\n",
    "    for i in range(1,len(your_mesh0.data)):\n",
    "        temp0=np.concatenate((temp0,your_mesh0.data[i][1]), axis=0)\n",
    "    Pointset0 = np.unique(temp0, axis=0)\n",
    "    neigh0=[]\n",
    "    N=len(Pointset0)\n",
    "    for i in range(len(Pointset0)):\n",
    "        lst=[]\n",
    "        for j in range(len(your_mesh0.data)):\n",
    "            if Pointset0[i].tolist() in your_mesh0.data[j][1].tolist():\n",
    "                for k in range(3):\n",
    "                    if Pointset0[i].tolist()!=your_mesh0.data[j][1][k].tolist():\n",
    "                        lst.append(your_mesh0.data[j][1][k].tolist())\n",
    "        lst=unique(lst)\n",
    "        neigh0.append(lst)\n",
    "    neigh0=unique(neigh0)\n",
    "    #gets point and and neigh of deformed\n",
    "    print('getting deformed')\n",
    "    your_mesh1 = mesh.Mesh.from_file(deformed)\n",
    "    temp1=your_mesh1.data[0][1]\n",
    "    for i in range(1,len(your_mesh1.data)):\n",
    "        temp1=np.concatenate((temp1,your_mesh1.data[i][1]), axis=0)\n",
    "    Pointset1 = np.unique(temp1, axis=0)\n",
    "    neigh1=[]\n",
    "    for i in range(N):\n",
    "        lst=[]\n",
    "        for j in range(len(your_mesh1.data)):\n",
    "            if Pointset1[i].tolist() in your_mesh1.data[j][1].tolist():\n",
    "                for k in range(3):\n",
    "                    if Pointset1[i].tolist()!=your_mesh1.data[j][1][k].tolist():\n",
    "                        lst.append(your_mesh1.data[j][1][k].tolist())\n",
    "                        lst=unique(lst)\n",
    "        neigh1.append(lst)\n",
    "        neigh1=unique(neigh1)\n",
    "     #calculates the matrix of the angles\n",
    "    C=np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i!=j:\n",
    "                temp=intersection(neigh0[i],neigh0[j])\n",
    "                if len(temp)==2:\n",
    "                    C[i,j]=abs(1/np.tan(calculate_angle(temp[0],Pointset0[i],Pointset0[j])))+abs(1/np.tan(calculate_angle(temp[1],Pointset0[i],Pointset0[j])))\n",
    "    #calculates real neigh\n",
    "    print('calculating real neigh')\n",
    "    neigh=[1]*N\n",
    "    for i in range(N):\n",
    "        neigh[i]=[j for j in range(N) if C[i,j]!=0]\n",
    "    print('calculating T')\n",
    "    #calculates T\n",
    "    T=np.zeros([N,3,3])\n",
    "    for i in range(N):\n",
    "        for a in range(3):\n",
    "            for b in range(3):\n",
    "                temp0=0\n",
    "                temp1=0\n",
    "                for j in neigh[i]: \n",
    "                        p0=Pointset0[i]-Pointset0[j]\n",
    "                        p1=Pointset1[i]-Pointset1[j]\n",
    "                        temp0=temp0+C[i,j]*p0[b]*p1[a]\n",
    "                        temp1=temp1+C[i,j]*p0[b]*p0[b]\n",
    "                T[i,a,b]=temp0/temp1\n",
    "    #T=np.nan_to_num(T,nan=1)\n",
    "    R=np.zeros([N,3,3])\n",
    "    S=np.zeros([N,3,3])\n",
    "    dR=np.zeros([N,N,3,3])\n",
    "    temp=np.zeros([N,3,3])\n",
    "    print('calculating R and S')\n",
    "    #calculates R and S\n",
    "    for i in range(N):\n",
    "        temp[i]=np.matmul(T[i].T,T[i])\n",
    "        D,Q=np.linalg.eigh(temp[i])\n",
    "        D=np.diag(D)**0.5\n",
    "        #D=np.nan_to_num(D,nan=1)\n",
    "        S[i]=np.matmul(Q.T,np.matmul(D,Q))\n",
    "        R[i]=np.matmul(T[i],np.linalg.inv(S[i]))\n",
    "        R[i][R[i]==np.inf] = 999\n",
    "\n",
    "    print('calculating RIMD')\n",
    "    RIMDi0=S[0]\n",
    "    for j in neigh[0]:\n",
    "        dR[0][j]=np.matmul(R[0].T,R[j])\n",
    "        RIMDi0=np.concatenate((dR[0,j],RIMDi0),axis=1)\n",
    "    RIMD=RIMDi0\n",
    "    for i in range(N):\n",
    "        RIMDi=S[i]\n",
    "        for j in neigh[i]:\n",
    "            dR[i][j]=np.matmul(R[i].T,R[j])\n",
    "            RIMDi=np.concatenate((dR[i,j],RIMDi),axis=1)\n",
    "        RIMD=np.concatenate((RIMD,RIMDi),axis=1)\n",
    "    M=len(RIMD[0,:])\n",
    "    RIMD=RIMD.reshape(3*M)\n",
    "    E=np.zeros([N,N,3])\n",
    "    for i in range(N):\n",
    "        for j in neigh[i]:\n",
    "            E[i,j,:]=Pointset0[i]-Pointset0[j]\n",
    "    shape=np.zeros([len(your_mesh0.data),3])\n",
    "    for i in range(len(your_mesh0.data)):\n",
    "        for k in range(3):\n",
    "            for j in range(len(Pointset0)):\n",
    "                if your_mesh0.data[i][1][k].tolist()==Pointset0[j].tolist():\n",
    "                    shape[i,k]=j\n",
    "                   \n",
    "    \n",
    "    return RIMD,neigh,E,C,shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efd8e62-33b5-4145-99e3-f47519a7de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_STL(newRIMD,neigh,E,C,shape,name):\n",
    "    newRIMD=newRIMD.reshape(3,int(len(newRIMD)/3))\n",
    "    N=len(neigh)\n",
    "    newS=np.zeros([N,3,3])\n",
    "    newdR=np.zeros([N,N,3,3])\n",
    "    k=0\n",
    "    for i in range(len(neigh)):\n",
    "        for j in neigh[i]:\n",
    "            newdR[i,j]=np.exp(newRIMD[:,k:k+3])\n",
    "            k=k+3\n",
    "        newS[i]=newRIMD[:,k:k+3]\n",
    "\n",
    "    newR=np.zeros([N,3,3])\n",
    "    for i in range(N):\n",
    "        newR[i,:,:]=np.eye(3)\n",
    "\n",
    "    Energy=1\n",
    "    Energyold=0\n",
    "    while abs(Energy-Energyold)/abs(Energy)>0.03:\n",
    "        opt_model = plp.LpProblem()\n",
    "        Ctilde=np.zeros(N)\n",
    "        for i in range(N):\n",
    "            Ctilde[i]=1/len(neigh[i])\n",
    "        x_vars  = {(i,h): plp.LpVariable(cat=plp.LpContinuous,  \n",
    "               name=\"x_{0}_{1}\".format(i,h)) for i in range(N) for h in range(3)}\n",
    "\n",
    "        temp=np.zeros([N,3])\n",
    "        for j in range(N):\n",
    "            for k in neigh[j]:\n",
    "                temp3=0\n",
    "                temp0=0\n",
    "                temp1=0\n",
    "                for s in neigh[k]:\n",
    "                    temp0=temp0+Ctilde[k]*np.matmul(newR[s],np.matmul(newdR[s,k],newS[k]))\n",
    "                for i in neigh[j]:\n",
    "                    temp1=temp1+Ctilde[j]*np.matmul(newR[i],np.matmul(newdR[i,j],newS[j]))\n",
    "                temp3=temp3+C[j,k]*np.matmul(temp0+temp1,E[j,k])\n",
    "            temp[j,:]=temp3\n",
    "\n",
    "        constraints = {j : opt_model.addConstraint(\n",
    "        plp.LpConstraint(\n",
    "             e=plp.lpSum(C[j,k] * (x_vars[j,h]-x_vars[k,h] )for k in neigh[j]),\n",
    "             sense=plp.LpConstraintEQ,\n",
    "             rhs=temp[j][h],\n",
    "             name=\"constraint_{0}_{1}\".format(j,h)))\n",
    "           for j in range(N) for h in range(3)}\n",
    "        opt_model.solve(plp.PULP_CBC_CMD(msg=0))\n",
    "        newP=np.zeros([N,3])\n",
    "        newE=np.zeros([N,N,3])\n",
    "        for i in range(N):\n",
    "            for k in range(3):\n",
    "                newP[i,k]=plp.value(x_vars[i,k])\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                newE[i,j,:]=newP[i,:]-newP[j,:]\n",
    "        Q=np.zeros([N,3,3])\n",
    "        for i in range(N):\n",
    "            temp1=0\n",
    "            for j in neigh[i]:\n",
    "                temp0=0\n",
    "                for k in neigh[j]:\n",
    "                    temp0=temp0+C[j,k]*np.outer(E[j,k],newE[j,k].T)\n",
    "                temp1=temp1+Ctilde[j]*np.matmul(newdR[i,j],np.matmul(newS[i],temp0))\n",
    "            Q[i]=temp1\n",
    "            U, s, Vh = np.linalg.svd(Q[i])\n",
    "            newR[i]=np.matmul(U,Vh)\n",
    "        Energyold=Energy\n",
    "        Energy=0\n",
    "        for i in range(N):\n",
    "            temp1=0\n",
    "            for j in neigh[i]:\n",
    "                temp0=0\n",
    "                for k in neigh[j]:\n",
    "                    temp0=temp0+C[j,k]*np.linalg.norm(newE[j,k]-np.matmul(np.matmul(newR[i],newdR[i,j]),np.matmul(newS[j],E[j,k])))**2\n",
    "                temp1=temp1+Ctilde[j]*temp0\n",
    "            Energy=Energy+temp1\n",
    "\n",
    "    shape=shape.astype(np.int64)\n",
    "    newmesh = np.zeros(len(shape), dtype=mesh.Mesh.dtype)\n",
    "    for i in range(len(shape)):\n",
    "        newmesh['vectors'][i]=np.array([newP[j].tolist() for j in shape[i].tolist()])\n",
    "    mesh.Mesh(newmesh).save(name, mode=stl.Mode.ASCII)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b39bfc-3752-4cde-92eb-b16f0b945871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting reference\n",
      "getting deformed\n",
      "calculating real neigh\n",
      "calculating T\n",
      "calculating R and S\n",
      "calculating RIMD\n"
     ]
    }
   ],
   "source": [
    "RIMD,neigh,E,C,shape=createRIMD('cube.stl','Parallelepiped.stl')\n",
    "def pseudonormalize(data,a):\n",
    "    return 2*a*(data-np.min(data))/(np.max(data)-np.min(data))-a,np.max(RIMD),np.min(RIMD)\n",
    "\n",
    "RIMDtilde,Max,Min=pseudonormalize(RIMD,0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9d29c5-c385-414f-9003-a7231cefb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    N=432\n",
    "    \n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, N)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = self.tanh(self.fc21(hidden))\n",
    "        return loc_img\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(N,hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(N)\n",
    "        # compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale\n",
    "\n",
    "        \n",
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super().__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            # decode the latent code z\n",
    "            loc_img = self.decoder(z)\n",
    "            pyro.sample(\"obs\", dist.AffineBeta(loc_img+1,1-loc_img,-1,2).to_event(1), obs=x)\n",
    "            \n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder(x)\n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            \n",
    "    def fitted(self, x):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img\n",
    "\n",
    "def train(svi, train_set, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x in train_set:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "        \n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_set)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train\n",
    "\n",
    "def evaluate(svi, test_set, use_cuda=False):\n",
    "\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for x in test_set:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "\n",
    "        hello=vae.fitted(x)\n",
    "        \n",
    "    return hello\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a652a8a8-d8eb-4795-83e4-35dc2d18a20c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[180]' is invalid for input of size 432\n        Trace Shapes:        \n         Param Sites:        \n encoder$$$fc1.weight 400 180\n   encoder$$$fc1.bias     400\nencoder$$$fc21.weight  50 400\n  encoder$$$fc21.bias      50\nencoder$$$fc22.weight  50 400\n  encoder$$$fc22.bias      50\n        Sample Sites:        \n            data dist       |\n                value 432   |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mVAE.guide\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pyro\u001b[38;5;241m.\u001b[39mplate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# use the encoder to get the parameters used to define q(z|x)\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     z_loc, z_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# sample the latent code z\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# compute the hidden units\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[180]' is invalid for input of size 432",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# training loop\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 28\u001b[0m     total_epoch_loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_CUDA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     train_elbo\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m-\u001b[39mtotal_epoch_loss_train)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m#print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\u001b[39;00m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(svi, train_set, use_cuda)\u001b[0m\n\u001b[1;32m     99\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# do ELBO gradient and accumulate loss\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# return epoch loss\u001b[39;00m\n\u001b[1;32m    104\u001b[0m normalizer_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_set)\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_trace, guide_trace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_particle \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/infer/elbo.py:182\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles):\n\u001b[0;32m--> 182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mget_importance_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/infer/enum.py:60\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     58\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m unwrapped_guide\u001b[38;5;241m.\u001b[39mget_traces()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mpoutine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detach:\n\u001b[1;32m     64\u001b[0m         guide_trace\u001b[38;5;241m.\u001b[39mdetach_()\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:180\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         exc \u001b[38;5;241m=\u001b[39m exc_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    179\u001b[0m         exc \u001b[38;5;241m=\u001b[39m exc\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_RETURN\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_RETURN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39mret\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mVAE.guide\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m pyro\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pyro\u001b[38;5;241m.\u001b[39mplate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# use the encoder to get the parameters used to define q(z|x)\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     z_loc, z_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# sample the latent code z\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     pyro\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent\u001b[39m\u001b[38;5;124m\"\u001b[39m, dist\u001b[38;5;241m.\u001b[39mNormal(z_loc, z_scale)\u001b[38;5;241m.\u001b[39mto_event(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/sissa/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# compute the hidden units\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftplus(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[180]' is invalid for input of size 432\n        Trace Shapes:        \n         Param Sites:        \n encoder$$$fc1.weight 400 180\n   encoder$$$fc1.bias     400\nencoder$$$fc21.weight  50 400\n  encoder$$$fc21.bias      50\nencoder$$$fc22.weight  50 400\n  encoder$$$fc22.bias      50\n        Sample Sites:        \n            data dist       |\n                value 432   |"
     ]
    }
   ],
   "source": [
    "# Run options\n",
    "LEARNING_RATE = 1.0e-3\n",
    "USE_CUDA = False\n",
    "# Run only for a single iteration for testing\n",
    "NUM_EPOCHS = 1000\n",
    "TEST_FREQUENCY = 10\n",
    "\n",
    "train_loader=[]\n",
    "train_loader.append(torch.tensor(RIMDtilde).float())\n",
    "test_loader=train_loader\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=USE_CUDA)\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    #print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "'''\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))\n",
    "'''\n",
    "print(torch.sum(torch.tensor(RIMDtilde)**2))\n",
    "print(torch.sum((torch.tensor(RIMDtilde)-evaluate(svi,train_loader,False))**2)/len(RIMDtilde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07580667-b766-4b76-bdaf-fbf07ac34214",
   "metadata": {},
   "outputs": [],
   "source": [
    "newRIMDtilde=evaluate(svi,train_loader,False)\n",
    "newRIMDtilde=newRIMDtilde.detach().numpy()\n",
    "newRIMDtilde,*_=pseudonormalize(newRIMDtilde,0.9)\n",
    "def pseudodenormalize(data,a,Max,min):\n",
    "    return (data+a)/(2*a)*(Max-Min)-Min\n",
    "\n",
    "newRIMD=pseudodenormalize(newRIMDtilde,0.9,Max,Min)\n",
    "print(newRIMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca148633-a706-4b07-a127-90ef4efeab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_STL(newRIMD,neigh,E,C,shape,'newmesh.stl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf74acd-deb6-4161-8b30-a4ed888bdd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31bf28-49da-41b8-9060-ebb1fefbd0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39967648-1d04-4cd8-afe3-71b925548cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
